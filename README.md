# Codex - Sistema de Assistente Virtual com RAG

Este projeto implementa um sistema de assistente virtual inteligente utilizando tÃ©cnicas de RAG (Retrieval-Augmented Generation) para fornecer respostas precisas e contextualizadas sobre pedidos e produtos.

## Funcionalidades

- Processamento de consultas em linguagem natural
- Sistema RAG para recuperaÃ§Ã£o de informaÃ§Ãµes relevantes
- API REST para integraÃ§Ã£o com outros sistemas
- Suporte a mÃºltiplos formatos de dados
- Processamento assÃ­ncrono de consultas
- Sistema de cache para otimizaÃ§Ã£o de performance

## Tecnologias Utilizadas

- Python 3.8+
- FastAPI
- LangChain
- OpenAI GPT
- FAISS (Facebook AI Similarity Search)
- Pandas
- Uvicorn

## PrÃ©-requisitos

- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)
- Ambiente virtual Python (recomendado)

## InstalaÃ§Ã£o

1. Clone o repositÃ³rio:

```bash
git clone [URL_DO_REPOSITÃ“RIO]
cd codex-test
```

2. Crie e ative um ambiente virtual:

```bash
python -m venv venv
# Windows
.\venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

3. Instale as dependÃªncias:

```bash
pip install -r requirements.txt
```

4. Configure as variÃ¡veis de ambiente:
   Crie um arquivo `.env` na raiz do projeto com as seguintes variÃ¡veis:

```
OPENAI_API_KEY=sua_chave_api
```

## Estrutura do Projeto

```
codex-test/
â”œâ”€â”€ data/               # DiretÃ³rio para armazenamento de dados
â”œâ”€â”€ deploy/            # Scripts e configuraÃ§Ãµes de deploy
â”œâ”€â”€ src/               # CÃ³digo fonte principal
â”‚   â”œâ”€â”€ api.py         # ImplementaÃ§Ã£o da API REST
â”‚   â”œâ”€â”€ assistente.py  # LÃ³gica principal do assistente
â”‚   â”œâ”€â”€ rag_system.py  # Sistema RAG
â”‚   â”œâ”€â”€ prompts.py     # Templates de prompts
â”‚   â””â”€â”€ static/        # Arquivos estÃ¡ticos
â”œâ”€â”€ tests/             # Testes automatizados
â”œâ”€â”€ requirements.txt   # DependÃªncias do projeto
â””â”€â”€ README.md         # DocumentaÃ§Ã£o
```

## Uso

1. Inicie o servidor:

```bash
uvicorn src.api:app --reload
```

2. A API estarÃ¡ disponÃ­vel em `http://localhost:8000`

3. Endpoints disponÃ­veis:

- `POST /chat`: Envia uma mensagem para o assistente
- `GET /health`: Verifica o status do servidor

## DocumentaÃ§Ã£o da API

### POST /chat

Envia uma mensagem para o assistente e recebe uma resposta.

**Request Body:**

```json
{
  "message": "Qual Ã© o status do pedido 123?",
  "session_id": "optional_session_id"
}
```

**Response:**

```json
{
  "response": "Resposta do assistente",
  "session_id": "session_id"
}
```

## ğŸ§ª Testes

Para executar os testes:

```bash
pip install -r requirements-dev.txt
pytest
```

## Fluxo de Trabalho

1. O usuÃ¡rio envia uma consulta atravÃ©s da API
2. O sistema RAG processa a consulta e recupera informaÃ§Ãµes relevantes
3. O assistente gera uma resposta contextualizada
4. A resposta Ã© retornada ao usuÃ¡rio

## Autores

- NÃ­colas Mikael - _Desenvolvimento Inicial_

## ğŸ™ Agradecimentos

- OpenAI pelo modelo GPT
- Comunidade LangChain
- Todos os contribuidores do projeto
